{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "e824b072-adc1-40c9-aa1b-c2a2cf9e4a72",
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\n\ndef classification_training(data):\n    \n    # Подготовка целевой переменной\n    y = (data['mental_wellness_index_0_100'] >= 15).astype(int)\n\n    # Подготовка признаков - все, кроме целевого ('mental_wellness_index_0_100') и идентификатора ('user_id')\n    feature_columns = [col for col in data.columns if col not in ['mental_wellness_index_0_100', 'user_id']]\n    X = data[feature_columns].copy()\n\n    # Обработка категориальных признаков с использованием LabelEncoder\n    categorical_features = ['gender', 'occupation', 'work_mode']\n    le_dict = {}\n    for feature in categorical_features:\n        if feature in X.columns:\n            le = LabelEncoder()\n            X.loc[:, feature] = le.fit_transform(X[feature].astype(str))\n            le_dict[feature] = le\n\n    # Разделение датасета на тренировочную и тестовую выборку\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y,\n        test_size=0.25,\n        shuffle=True,\n        random_state=37\n    )\n\n    # Создание словаря-сетки для GridSearchCV\n    param_grid = {\n        'n_estimators': [50, 100, 200], \n        'max_depth': [None, 10, 20], \n        'min_samples_split': [2, 5, 10], \n        'min_samples_leaf': [1, 2, 4], \n        'max_features': ['sqrt', 'log2'] \n    }\n\n    # Создание экземпляра класса случайного леса\n    rf_base = RandomForestClassifier(\n        random_state=37, # Для воспроизводимости\n        n_jobs=-1 # Использовать все доступные ядра\n    )\n\n    # Выполнение поиска оптимального набора гиперпараметров\n    grid_search = GridSearchCV(\n        estimator=rf_base,\n        param_grid=param_grid,\n        scoring='f1', \n        cv=5, \n        n_jobs=-1, \n        verbose=0 \n    )\n\n    # Обучаем GridSearchCV на тренировочных данных\n    grid_search.fit(X_train, y_train)\n\n    # Вывод оптимального набора гиперпараметров\n    print(\"Л:\")\n    for param, value in grid_search.best_params_.items():\n        print(f\"  {param}: {value}\")\n\n    # Обучение финальной модели с оптимальным набором гиперпараметров\n    best_rf_model = grid_search.best_estimator_\n\n    # Предсказания и оценка финальной модели на тестовой выборке\n    y_pred = best_rf_model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n\n    # Вывод значений метрик\n    print(f\"RF: {accuracy:.4f}; {f1:.4f}\")\n\ndata = pd.read_csv(\"DB_3_cleaned.csv\") # Замените на путь к вашему датасету\nclassification_training(data)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Л:\n  max_depth: None\n  max_features: sqrt\n  min_samples_leaf: 2\n  min_samples_split: 10\n  n_estimators: 50\nRF: 0.9596; 0.9545\n"
        }
      ],
      "execution_count": 1
    },
    {
      "id": "a5f1baf1-933e-40a8-a1c4-5b427e74bce9",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}